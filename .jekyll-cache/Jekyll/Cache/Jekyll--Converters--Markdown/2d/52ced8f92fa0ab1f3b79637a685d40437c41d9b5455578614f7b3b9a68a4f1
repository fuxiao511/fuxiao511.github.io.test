I"+<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    /* L1 MMU when running nested */
    struct kvm_mmu guest_mmu;
    /* vcpu-&gt;arch.guest_mmu isn't used when !tdp_enabled. */
</code></pre></div></div>

<p>init_kvm_tdp_mmu</p>

<pre><code class="language-mermaid">classDiagram

	kvm_mmu &lt;|-- kvm_vcpu_arch

	class kvm_mmu_page_role {
	
	}
	class kvm_mmu_page {
        union kvm_mmu_page_role role;
        u64 *spt; 
        对应的SPT/EPT页地址,该域可以指向一个lower-level shadow pages，也可以指向真正的数据page。
        gfn_t *gfns; 
        //gfn：在直接映射中存储线性地址的基地址
	}
	class kvm_vcpu_arch {
		+Struct walk_mmu
		+Struct mmu
		+struct kvm_mmu_memory_cache mmu_pte_list_desc_cache
		+struct kvm_mmu_memory_cache mmu_page_cache
		+struct kvm_mmu_memory_cache mmu_page_header_cache
		
	}
	class kvm_mmu{
          +String beakColor
          +swim()
          +quack()
	}

</code></pre>

<p>以<strong>init_kvm_tdp_mmu</strong>为例</p>

<p>struct kvm_mmu {</p>

<p>​	root_hpa：存储Paging Structure中根目录的结构，如EPT中的eptp</p>

<p>​	root_level：Host Paging Structure中根目录的级别（如64位支持paging的系统可以支持level=4的页结构）</p>

<p>​	shadow_root_level：SPT Paging Structure中根目录的级别（如64位支持paging的系统可以支持level=4的EPT页结构）</p>

<p>​	union kvm_mmu_page_role base_role;</p>

<p>​	direct_map=true：该MMU是否保证存储的页结构和VCPU使用的页结构的一致性。如果为true则每次MMU内容时都会刷新VCPU的TLB，否则需要手动同步。</p>

<p>​	last_pte_bitmap：上一次访问的pte</p>

<p>​	page_fault = kvm_tdp_page_fault;</p>

<p>​	sync_page = nonpaging_sync_page;</p>

<p>invlpg = NULL;  在<strong>init_kvm_tdp_mmu</strong>中置为NULL</p>

<p>get_guest_pgd = get_cr3;</p>

<p>get_pdptr = kvm_pdptr_read;</p>

<p>inject_page_fault = kvm_inject_page_fault;</p>

<p>gva_to_gpa = paging64_gva_to_gpa;</p>

<p>}</p>

<p>direct含义：</p>

<p>direct mapping of virtual to physical mapping at gfn，used for real mode and two-dimensional paging</p>

<p>当使用常规的mmu或者TDP时，direct为true；当guest paging disabled（gpa-&gt;hpa）或者嵌套虚拟化的时候，使用shadow mode</p>

<p>is_cr0_pg CR0.PG位，启动分页机制</p>

<p>​			PE位，处于保护模式，否则处于实模式</p>

<p>CR4.PAE 启用PAE<strong>Physical-Address Extension</strong>，支持2MB超级页</p>

<p>role.has_4_byte_gpte = false;  所以启用了PAE，使用paging64_gva_to_gpa</p>

<pre><code class="language-mmu.txt">Linux memory management code must be in control of guest memory so that swapping, page migration, page merging, transparent hugepages, and similar features work without change
dirty tracking: report writes to guest memory to enable live migration and framebuffer-based displays

gpte  guest pte (referring to gfns)
spte  shadow pte (referring to pfns)

当使用常规的mmu或者TDP时，使用direct mode
当guest paging disabled（gpa-&gt;hpa）或者嵌套虚拟化的时候，使用shadow mode

mmu.c和paging_tmpl.h模拟的硬件支持传统的2/3/4级 x86 mmu硬件，支持global page、pae、pse、pse36、cr0.wp, and 1GB pages.

hva可以是匿名内存、file backend内存、device内存，也可以随时被宿主机分页

mmu硬件靠事件驱动：
虚拟机事件：写cr3，invlpg、invlpga、访问不存在或者保护的页
宿主机事件：gpa-&gt;hpa页表改变（gpa-&gt;hva或者hva-&gt;hpa都有影响），内存压力

影子页struct kvm_mmu_page包含512个spte，可以是叶子节点和非叶子节点的混合
叶子节点对应一个或者两个翻译项（A leaf spte corresponds to either one or two translations encoded into one paging structure entry.  ）

 Non-nested guests:
  nonpaging:     gpa-&gt;hpa
  paging:        gva-&gt;gpa-&gt;hpa
  paging, tdp:   (gva-&gt;)gpa-&gt;hpa
 Nested guests:
  non-tdp:       ngva-&gt;gpa-&gt;hpa  (*)
  tdp:           (ngva-&gt;)ngpa-&gt;gpa-&gt;hpa
  
 影子页面struct kvm_mmu_page包含以下信息：
 role.level 1表示影子页表中的spte指向4K的页面，2表示指向2M页面，3指向1G页面
 role.direct 1表示影子页表中的叶子spte指向的是线性地址。如以下场景：real mode translation, large guest pages backed by small host pages, and gpa-&gt;hpa translations when NPT or EPT is active.  还不理解其他为0的场景
 role.quadrant: 当role.gpte_is_8_bytes=0（即虚拟机是32位，宿主机是64位），虚拟机每4K也包含1024个pte，宿主机每4K包含522个pte；
 	对于32位虚拟机的第一级页表，role.quadrant=0或者1，表示第0或者第1个 512-gpte block
 	对于32位虚拟机的第二级页表，role.quadrant=0/1/2/3，每个quadrant表示1G虚拟地址
role.gpte_is_8_bytes: 1表示gpte使用64位，即虚拟机使用64位CPU；改为role.has_4_byte_gpte=0
gfn：线性转换的frame number，如果role.direct=0表示guest页表（被本page页shadow的guest页表）
spt：指向可被kvm和硬件访问的shadow page table，spt里的spte指向guest page或者指向下一级的shadow page，spt像物理机的pt一样构成一个页表结构有向图，shadow page作为节点，guest page为叶子
gfns：512个guest frame number的队列，用于pte-&gt;gfn的反向映射，当role.direct=1时，可以直接使用gfn变量计算，这个队列就不需要了
root_count
parent_ptes：反向映射，指向本page页的pte，如果bit0为1，表示有多个pte指向本page
unsync：等价于pte被更改，但是tlb还没有被flush，在虚拟机执行invlpg时同步
clear_spte_count
write_flooding_count

同步和未同步的pages
模拟tlb flushes and page invalidations (invlpg).
</code></pre>

<h2 id="kvm_mmu">kvm_mmu</h2>

<ul>
  <li>guest_mmu 嵌套情况下，L1虚拟机的mmu，非嵌套情况下也初始化</li>
  <li>nested_mmu 嵌套情况下，L2虚拟机的mmu，非嵌套情况下不初始化</li>
  <li>root_mmu 非嵌套情况下的L1虚拟机的mmu</li>
  <li>指针：</li>
  <li>mmu</li>
  <li>walk_mmu</li>
  <li>
    <p>kvm_mmu_create初始化的时候将mmu和walk_mmu都指向了root_mmu</p>
  </li>
  <li>kvm_init_mmu在创建vcpu的时候初始化mmu，mmu是L2嵌套虚拟机的，还是L1虚拟机的，在这里体现
    <ul>
      <li>init_kvm_tdp_mmu  初始化L1虚拟机单个vcpu的mmu</li>
      <li>vcpu未开启paging，虚拟地址就是物理地址，nonpaging_gva_to_gpa不进行转换</li>
      <li>vcpu开启paging，虚拟机是64位和32位pae情况下，has_4_byte_gpte=false
        <ul>
          <li>都使用paging64_gva_to_gpa，通过软件遍历虚拟机的页表，获取gpa</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>​</p>

<p>struct kvm_memory_slot {
    gfn_t base_gfn; // 该slot对应虚拟机页框的起点
    unsigned long npages; // 该slot中有多少个页
    unsigned long *dirty_bitmap; // 脏页的bitmap
    struct kvm_arch_memory_slot arch; // 体系结构相关的结构
    unsigned long userspace_addr; // 对应HVA的地址
    u32 flags; // slot的flag
    short id; // slot识别id
};</p>

<p>kvm_mmu_page_role  跟踪二级页表的属性，是kvm_cpu_role的子集，减小kvm_memory_slot.arch.gfn_track的大小</p>

<p>比如 allows allocating 2 bytes per gfn instead of 4 bytes per gfn.</p>

<p>gfn_track</p>

:ET